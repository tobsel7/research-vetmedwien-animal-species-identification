{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e864ae4-ad4a-451a-b17e-5444f28fdb6b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset\"\n",
    "subtitle: \"Testing the Pre-trained Inception-ResNet-v2 Computer Vision Model on a Google Image Dataset\"\n",
    "date: 2025-09-03\n",
    "keywords: [\"machine learning\", \"reproducibility\", \"animal species classification\", \"computer vision\", \"neural networks\", \"cnn\", \"resnet\", \"tensorflow\", \"wildlife monitoring\"]\n",
    "exports: \n",
    "  - format: pdf\n",
    "    template: arxiv_nips\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01c608-842d-4354-a254-c21ad9dfab3a",
   "metadata": {},
   "source": [
    "+++ {\"part\": \"abstract\"}\n",
    "This experiment attempts to reproduce the results of the paper [Automated detection of European wild mammal species in camera trap images with an existing and pre-trained computer vision model](doi:10.1007/s10344-020-01404-y), \n",
    "which tests the pretrained Google Inception-ResNet-v2 model for predicting animal species.\n",
    "We describe the required software, image loading processes, model outputs. Furthermore we calculate prediction global and per-class prediction accuracies and compare them to the metrics from the original paper.\n",
    "+++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37d481-9220-4329-9229-6f674b5a0e31",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3e352-9555-405e-a75a-857478b0360a",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4dde4-7acb-4884-b968-a4f1640595b1",
   "metadata": {},
   "source": [
    "Carl et al. do not supply great insight into the runtime environment. This is likely due to the standardized way the model can be used through the TensorFlow library. To maximize the readability and reproducibility of the experiment, a minimal setup was chosen, defining all necessary code, data, and requirements in one GitHub project.\n",
    "State-of-the-art Python packages are chosen, installed, and imported. The exact versions are shown in {numref}`table-requirements`. The Jupyter notebook is run locally on a Thinkpad T14 with an AMD Ryzen 5 PRO 5650U processor, 16 GB of memory, and Linux Mint 22.1 installed. No GPU was used, but it can be expected that the results would not change if one were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d66bb14-108a-4841-861a-b42ba643461c",
   "metadata": {
    "label": "pip-install",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib==1.0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: Pillow==11.3.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: numpy==2.1.3 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: pandas==2.3.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: tensorflow==2.19.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.19.0)\n",
      "Requirement already satisfied: scikit-learn==1.7.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: matplotlib==3.10.5 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.10.5)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from pandas==2.3.1->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from pandas==2.3.1->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tobsel/jupyter/lib/python3.12/site-packages (from pandas==2.3.1->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (3.11.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 6)) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from scikit-learn==1.7.1->-r requirements.txt (line 7)) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from scikit-learn==1.7.1->-r requirements.txt (line 7)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from scikit-learn==1.7.1->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from matplotlib==3.10.5->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tobsel/jupyter/lib/python3.12/site-packages (from matplotlib==3.10.5->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from matplotlib==3.10.5->-r requirements.txt (line 8)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from matplotlib==3.10.5->-r requirements.txt (line 8)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from matplotlib==3.10.5->-r requirements.txt (line 8)) (3.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/tobsel/jupyter/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (14.1.0)\n",
      "Requirement already satisfied: namex in /home/tobsel/jupyter/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/tobsel/jupyter/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 6)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!python3.12 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924ea3ec-3bbb-4d52-abc8-3e0bb525a32e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 13:01:41.989680: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-11 13:01:41.992823: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-11 13:01:42.000486: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757588502.013231   17180 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757588502.016802   17180 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757588502.027391   17180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757588502.027403   17180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757588502.027405   17180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757588502.027406   17180 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-11 13:01:42.030815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# image & data processing\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import decode_predictions\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b4eec-e40d-49f3-a762-c6588b1b2cf5",
   "metadata": {},
   "source": [
    "# Model\n",
    "Once the Python runtime is set up and the packages are imported, the neural network can be instantiated and directly fit to the ImageNet dataset. This eliminates all model design and training work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13ca2a5-58e7-465a-b892-e01b22f3a3d3",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 13:01:44.301380: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = InceptionResNetV2(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2756fa1-5497-4169-93a1-7ff0cd856622",
   "metadata": {},
   "source": [
    "# Data\n",
    "For the experiment, 90 common animals are used. They are sourced from Google Images and provided in a labeled format in @banerjee2024animal. The Kaggle dataset is rather large. To mimic the original experiment setup, only 10 samples are used for each species, resulting in a total test sample size of 900 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c88843-7ffa-443b-9076-1c80ac52b33a",
   "metadata": {},
   "source": [
    "```{image} data/kaggle-90-different-animals/wombat/2a6c3fd292.jpg\n",
    ":align: center\n",
    ":alt: Example wildlife image (wombat)\n",
    ":width: 300px\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a09bccc-0d76-40f1-ac09-90cea5145796",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data/kaggle-90-different-animals\")\n",
    "GITHUB_PROJECT = \"https://github.com/tobsel7/research-vetmedwien-animal-species-identification\"\n",
    "model_input_size = model.input_shape[1:3] # the required image dimensions (299, 299)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e7d79-7fb5-42b9-b80b-de313d1b4c5e",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "The images are loaded with three color channels (RGB), resized to 299 by 299 pixels and converted into an 1-dimensional vector. The color intensities are scaled to be floating point numbers from 0 to 1. This is the minimal preprocessing required to fit the required input size of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40140f1-0592-413b-a60c-9aa9403ca6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normalized_image(path, target_size=model_input_size):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    return np.array(image) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd76cbc-623f-434e-bcf1-fa3801b4d712",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "wildlife_image_paths = []\n",
    "\n",
    "animal_species = sorted([d.name for d in DATA_PATH.iterdir() if d.is_dir()])\n",
    "\n",
    "for species_name in animal_species:\n",
    "    animal_image_folder = DATA_PATH / species_name # every species has its image folder\n",
    "    for image_path in animal_image_folder.glob(\"*.jpg\"):\n",
    "        image_array = load_normalized_image(image_path)\n",
    "        wildlife_image_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1c34b-5950-4d78-bbec-a6f9a540f6cd",
   "metadata": {},
   "source": [
    "The testing data is constructed by stacking the normalized image vectors and using the folder names as the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c43f760-8384-41d0-9138-501329a5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_images = [load_normalized_image(p) for p in wildlife_image_paths]\n",
    "animal_species = [p.parent.name for p in wildlife_image_paths]\n",
    "\n",
    "X_test = np.stack(animal_images, axis=0)\n",
    "y_true = animal_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03016731-0ae6-439a-940c-16ffd6f7afa4",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 299, 299, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c61ad-f992-446b-9b60-b72c2e764889",
   "metadata": {},
   "source": [
    "# Test\n",
    "The model yields a probability for each of the 1000 classes. The classes represent 1000 different classes taken from the ImageNet database. For this experiment, we use the output from the top neuron of the final softmax layer and compare its label to the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57705620-c7a5-416b-9393-57a72bf9ad80",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 13:02:05.551344: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 965530800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = [pred[0][1] for pred in decode_predictions(y_pred, top=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dc938-cbe0-42c5-937c-b2e2db96b132",
   "metadata": {},
   "source": [
    "When looking at the results, it becomes apparent that the model yields usable results. Almost all inference outputs are animal species somehow related to the one present in the image. This shows that the InceptionResNetV2 is generalizable to some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0b2297-2127-4b8f-bdd4-e02299daf908",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "species_recognition_result = pd.DataFrame({\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b09c22-5c7b-4126-8283-d32a367d547a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"figure/species_recognition_result_raw_short.md\", \"w\") as f:\n",
    "    f.write(\n",
    "        species_recognition_result.groupby(\"y_true\", as_index=False).first()[:10].to_markdown(index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353ed44-0309-4adc-87bf-f8845d10f55d",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: species_recognition_result_raw_short\n",
    ":align: center\n",
    "\n",
    "Subset of Inception-ResNet-v2 raw predictions\n",
    "```{include} figure/species_recognition_result_raw_short.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8e370-e4da-4ce2-9674-8b8379824f6a",
   "metadata": {},
   "source": [
    "## Label Mapping\n",
    "The main issue with this experiment is the set of classes known to the model, which do not match the dataset used for testing. This is not specific to this dataset, but it is very likely to happen in any kind of realistic setup. We manually define a mapping table to relate the model output label to the labels from the dataset. \n",
    "\n",
    "This mapping is done manually, as a best-effort approach following the Linnean system of taxonomy, and we acknowledge some shortcomings of it:\n",
    "\n",
    "- Some semantic information is lost as species are sometimes mapped to their families. (e.g., all bear species are mapped to bear)\n",
    "- The dataset contains images of species that are not directly related to any class from the model. (e.g., all bats, deers)\n",
    "\n",
    "\n",
    " We document all defined mappings in {numref}`table-imagenet-label-mapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f512d620-fdaa-42eb-a570-56e011303871",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "imagenet_to_kaggle = {\n",
    "    \"gazelle\": \"antelope\",\n",
    "    \"impala\": \"antelope\",\n",
    "    \"American_black_bear\": \"bear\",\n",
    "    \"brown_bear\": \"bear\",\n",
    "    \"ground_beetle\": \"beetle\",\n",
    "    \"leaf_beetle\": \"beetle\",\n",
    "    \"rhinoceros_beetle\": \"beetle\",\n",
    "    \"dung_beetle\": \"beetle\",\n",
    "    \"wild_boar\": \"boar\",\n",
    "    \"ringlet\": \"butterfly\",\n",
    "    \"monarch\": \"butterfly\",\n",
    "    \"sulphur_butterfly\": \"butterfly\",\n",
    "    \"lycaenid\": \"butterfly\",\n",
    "    \"Egyptian_cat\": \"cat\",\n",
    "    \"tabby\": \"cat\",\n",
    "    \"Siamese_cat\": \"cat\",\n",
    "    \"Persian_cat\": \"cat\",\n",
    "    \"lynx\": \"cat\",\n",
    "    \"water_buffalo\": \"cow\",\n",
    "    \"Dungeness_crab\": \"crab\",\n",
    "    \"red_deer\": \"deer\",\n",
    "    \"elk\": \"deer\",\n",
    "    \"Labrador_retriever\": \"dog\",\n",
    "    \"basset\": \"dog\",\n",
    "    \"Border_collie\": \"dog\",\n",
    "    \"Chihuahua\": \"dog\",\n",
    "    \"Bouvier_des_Flandres\": \"dog\",\n",
    "    \"Brittany_spaniel\": \"dog\",\n",
    "    \"English_setter\": \"dog\",\n",
    "    \"Greater_Swiss_Mountain_dog\": \"dog\",\n",
    "    \"Ibizan_hound\": \"dog\",\n",
    "    \"Mexican_hairless\": \"dog\",\n",
    "    \"tox_terrier\": \"dog\",\n",
    "    \"Pekinese\": \"dog\",\n",
    "    \"Pomeranian\": \"dog\", \n",
    "    \"golden_retriever\": \"dog\",\n",
    "    \"pug\": \"dog\",\n",
    "    \"ass\": \"donkey\",\n",
    "    \"mallard\": \"duck\",\n",
    "    \"bald_eagle\": \"eagle\",\n",
    "    \"golden_eagle\": \"eagle\",\n",
    "    \"African_elephant\": \"elephant\",\n",
    "    \"Indian_elephant\": \"elephant\",\n",
    "    \"Arctic_fox\": \"fox\",\n",
    "    \"red_fox\": \"fox\",\n",
    "    \"grey_fox\": \"fox\",\n",
    "    \"kit_fox\": \"fox\",\n",
    "    \"ibex\": \"goat\",\n",
    "    \"mountain_goat\": \"goat\",\n",
    "    \"Arabian_horse\": \"horse\",\n",
    "    \"Appaloosa\": \"horse\",\n",
    "    \"wallaby\": \"kangaroo\",\n",
    "    \"agama\": \"lizard\",\n",
    "    \"alligator_lizard\": \"lizard\",\n",
    "    \"banded_gecko\": \"lizard\",\n",
    "    \"Komodo_dragon\": \"lizard\",\n",
    "    \"whiptail\": \"lizard\", \n",
    "    \"American_lobster\": \"lobster\",\n",
    "    \"spiny_lobster\": \"lobster\",\n",
    "    \"house_mouse\": \"mouse\",\n",
    "    \"fiddler_crab\": \"crab\",\n",
    "    \"rock_crab\": \"crab\",\n",
    "    \"king_crab\": \"crab\",\n",
    "    \"magpie\": \"crow\",\n",
    "    \"jay\": \"crow\",\n",
    "    \"drake\": \"duck\",\n",
    "    \"tusker\": \"elephant\",\n",
    "    \"great_grey_owl\": \"owl\",\n",
    "    \"giant_panda\": \"panda\",\n",
    "    \"African_grey\": \"parrot\",\n",
    "    \"macaw\": \"parrot\",\n",
    "    \"sulphur-crested_cockatoo\": \"parrot\",\n",
    "    \"pelican\": \"pelecaniformes\",\n",
    "    \"black_stork\": \"pelecaniformes\",\n",
    "    \"king_penguin\": \"penguin\",\n",
    "    \"hog\": \"pig\",\n",
    "    \"red-backed_sandpiper\": \"sandpiper\",\n",
    "    \"redshank\": \"sandpiper\",\n",
    "    \"dowitcher\": \"sandpiper\",\n",
    "    \"great_white_shark\": \"shark\",\n",
    "    \"hammerhead\": \"shark\",\n",
    "    \"tiger_shark\": \"shark\",\n",
    "    \"horned_viper\": \"snake\",\n",
    "    \"ram\": \"sheep\",\n",
    "    \"bighorn\": \"sheep\",\n",
    "    \"vine_snake\": \"snake\",\n",
    "    \"king_snake\": \"snake\",\n",
    "    \"night_snake\": \"snake\",\n",
    "    \"Indian_cobra\": \"snake\",\n",
    "    \"ringneck_snake\": \"snake\",\n",
    "    \"rock_python\": \"snake\",\n",
    "    \"thunder_snake\": \"snake\",\n",
    "    \"fox_squirrel\": \"squirrel\",\n",
    "    \"black_swan\": \"swan\",\n",
    "    \"box_turtle\": \"turtle\",\n",
    "    \"loggerhead\": \"turtle\",\n",
    "    \"leatherback_turtle\": \"turtle\",\n",
    "    \"mud_turtle\": \"turtle\",\n",
    "    \"grey_whale\": \"whale\",\n",
    "    \"killer_whale\": \"whale\",\n",
    "    \"timber_wolf\": \"wolf\",\n",
    "    \"white_wolf\": \"wolf\"\n",
    "}\n",
    "\n",
    "species_recognition_result[\"y_pred_mapped\"] = species_recognition_result[\"y_pred\"].map(\n",
    "    lambda l: imagenet_to_kaggle.get(l, l) # safe map accessor (labels that are not present in the dict keys, remain unchanged)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1bb2ff-e885-4ca9-8095-ceff8fe1a675",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Carl et al. provide two kinds of performance metrics: overall model accuracy and the accuracy for each species. By grouping the samples by the true species, it is straightforward to calculate metrics that can be directly compared to the results from Carl et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54d64d76-4955-4fae-a9ff-2c5a6dd591a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "0.62"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "total_accuracy"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_accuracy = accuracy_score(species_recognition_result[\"y_true\"], species_recognition_result[\"y_pred_mapped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a917030d-7e9c-499f-bcbf-fcd60b4a9ba2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "group_accuracy = species_recognition_result.assign(\n",
    "    accuracy = species_recognition_result[\"y_true\"] == species_recognition_result[\"y_pred_mapped\"]\n",
    ").groupby(\"y_true\")[\"accuracy\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa4b1d98-c1f2-4dde-bf3f-caf6b167369e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "example_species = group_accuracy.reset_index().iloc[np.linspace(0, len(group_accuracy) - 1, 5, dtype=int)]\n",
    "example_species.columns = [\"species\", \"accuracy\"]\n",
    "\n",
    "example_rows = (\n",
    "    species_recognition_result.groupby(\"y_true\", as_index=False).first()\n",
    "    .loc[lambda df: df[\"y_true\"].isin(example_species[\"species\"])]\n",
    ")\n",
    "\n",
    "summary_table = pd.merge(example_rows, example_species, left_on=\"y_true\", right_on=\"species\")\n",
    "summary_table = summary_table[[\"y_true\", \"accuracy\"]]\n",
    "summary_table.columns = [\"species\", \"accuracy\"]\n",
    "summary_table.sort_values(by=\"accuracy\", inplace=True, ascending=False)\n",
    "\n",
    "summary_table = pd.concat([\n",
    "    summary_table,\n",
    "    pd.DataFrame([[\"...\", \"...\"]], columns=summary_table.columns),\n",
    "    pd.DataFrame([[\"TOTAL\", total_accuracy]], columns=summary_table.columns)\n",
    "], ignore_index=True)\n",
    "\n",
    "with open(\"figure/species_recognition_result_summary.md\", \"w\") as f:\n",
    "    f.write(summary_table.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f40159-ba3e-4f61-b036-ee8d976dbd79",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: species_recognition_result_summary\n",
    ":align: center\n",
    "\n",
    "Prediction accuracy for 5 different species and the total accuracy\n",
    "```{include} figure/species_recognition_result_summary.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367d710-47c1-44d8-8ab2-9f67b3d4dad9",
   "metadata": {},
   "source": [
    "Refer to {numref}`group_accuracy` for the group accuracies for each species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bc3b2-7243-4663-a109-44c1ceab5ca9",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1657b70-9021-4849-9e20-ad8d18353e74",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4cafb-91a2-42d0-84cd-12f62816805b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83559e-38b7-49ec-9582-6ecd1d9fbd72",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Dependency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d907ab-b266-40bf-a018-0fa32fc5c01e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "package_versions = {}\n",
    "with open(\"requirements.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"==\" in line:\n",
    "            pkg, ver = line.split(\"==\")\n",
    "            package_versions[pkg] = ver\n",
    "        else:\n",
    "            package_versions[line] = \"unknown\"\n",
    "            \n",
    "with open(\"figure/requirements.md\", \"w\") as f:\n",
    "    f.write(\n",
    "        pd.DataFrame({\n",
    "            \"package\": package_versions.keys(),\n",
    "            \"version\": package_versions.values()\n",
    "        }).to_markdown(index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29548eed-c3dc-42a5-9644-5cad8d7cea06",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: table-requirements\n",
    ":align: center\n",
    "\n",
    "Runtime dependencies\n",
    "```{include} figure/requirements.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef27d12-1ca3-47a4-86c8-631599cc9227",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Imagenet Label Mapping Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ff4fc51-db9e-4471-82ce-5d57cc0eb868",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"figure/imagenet_label_mapping.md\", \"w\") as f:\n",
    "    f.write(\n",
    "        pd.DataFrame({\n",
    "            \"imagenet label\": imagenet_to_kaggle.keys(),\n",
    "            \"mapped label\": imagenet_to_kaggle.values()\n",
    "        }).groupby(\"mapped label\")[\"imagenet label\"].apply(\n",
    "            lambda labels: \", \".join(labels)\n",
    "        ).reset_index().to_markdown(index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d822a-b350-4b6a-88ec-3decce53066f",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: table-imagenet-label-mapping\n",
    ":align: center\n",
    "\n",
    "Imagenet label mapping\n",
    "```{include} figure/imagenet_label_mapping.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1f8c9-6a23-4f9f-b603-42008a0a5089",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Inference Output Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fc0cdf-5032-40d7-9f29-7c213f19e781",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "github_animal_image_paths = [\n",
    "    f\"[{p.parent.name}]({GITHUB_PROJECT}/raw/main/{p})\"\n",
    "    for p in wildlife_image_paths\n",
    "]\n",
    "\n",
    "with open(\"figure/species_recognition_result.md\", \"w\") as f:\n",
    "    f.write(\n",
    "        pd.DataFrame({\n",
    "            \"truth\": github_animal_image_paths,\n",
    "            \"mapped prediction\": species_recognition_result[\"y_pred_mapped\"],\n",
    "            \"model prediction\": species_recognition_result[\"y_pred\"]\n",
    "        }).to_markdown(index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64815cc-1b85-4649-afeb-e5588e9d5ff9",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: species-recognition-result\n",
    ":align: center\n",
    "\n",
    "Inception-ResNet-v2 predictions\n",
    "```{include} figure/species_recognition_result.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e246b-12d4-42f5-94ca-5bb8f165de59",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Per-Class Accuracy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12780dd4-bce8-4ca0-bd93-f8e69964fd30",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"figure/group_accuracy.md\", \"w\") as f:\n",
    "    f.write(\n",
    "        group_accuracy.reset_index().rename(columns={\"y_true\": \"species\"}).to_markdown(index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4089ac6-989f-4b62-b7ba-1444d9f50f87",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: group_accuracy\n",
    ":align: center\n",
    "\n",
    "The prediction accuracy for each animal species\n",
    "```{include} figure/group_accuracy.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
