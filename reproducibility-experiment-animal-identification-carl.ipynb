{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e864ae4-ad4a-451a-b17e-5444f28fdb6b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset\"\n",
    "subtitle: \"Testing Inception-ResNet-v2 on a Public Google Image Dataset\"\n",
    "keywords: [\"machine learning\", \"reproducibility\", \"camera trap\", \"pre-trained model\", \"animal species classification\", \"computer vision\", \"neural networks\", \"cnn\", \"resnet\", \"tensorflow\", \"wildlife monitoring\"]\n",
    "exports: \n",
    "  - format: pdf\n",
    "    template: arxiv_two_column\n",
    "    output: document/reproducibility-experiment-animal-identification-carl.pdf\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01c608-842d-4354-a254-c21ad9dfab3a",
   "metadata": {},
   "source": [
    "+++ {\"part\": \"abstract\"}\n",
    "This study revisits the findings of Carl et al. {cite}`doi:10.1007/s10344-020-01404-y`, who evaluated the pre-trained Google Inception-ResNet-v2 model for automated detection of European wild mammal species in camera trap images. To assess the reproducibility and generalizability of their approach, we reimplemented the experiment from scratch using openly available resources and a different dataset consisting of 900 images spanning 90 species. After minimal preprocessing, we obtained an overall classification accuracy of 62%, closely aligning with the 71% reported in the original work despite differences in datasets. As seen in the original study, per-class performance varied substantially, ranging from 0% to 100% accuracy, highlighting limitations in generalization when labels do not align directly with ImageNet classes. Our results confirm that pretrained convolutional neural networks can provide a practical baseline for wildlife species identification but also reinforce the need for dataset-specific adaptation or transfer learning to achieve consistent, high-quality predictions.\n",
    "+++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37d481-9220-4329-9229-6f674b5a0e31",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "While biodiversity is decreasing at a rapid pace, the rise of specific species, be they invasive or predatory, concerns societies around the world. As a consequence, researchers and conservationists are interested in continuously monitoring wildlife populations in terms of their geographical distribution, size, and behavior. Researchers successfully deploy camera traps that can take photographs of passing animals without disturbing them {cite}`trolliet2014camera`. The photos are typically manually collected from the traps and annotated with the name of the species present in the image {cite}`10.1145/3615893.3628760`.\n",
    "\n",
    "Deep convolutional neural networks (CNNs) have emerged as a promising solution to automate this process, offering robust image classification capabilities. Building on prior work, this study evaluates the reproducibility of results reported by Carl et al. {cite}`doi:10.1007/s10344-020-01404-y`, who applied a pre-trained Inception-ResNet-v2 model for European mammal species detection in camera trap images. By reconstructing their experiment using a different dataset and a reproducible, open-source workflow, we examine both the reliability of the original findings and the generalizability of pretrained CNNs to broader wildlife monitoring scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4dde4-7acb-4884-b968-a4f1640595b1",
   "metadata": {},
   "source": [
    "# Experiment Setup\n",
    "\n",
    "We reimplemented the Python code for the experiment from scratch because all the necessary components (data {cite}`banerjee2024animal`, model {cite}`doi:10.48550/arXiv.1602.07261`, and metrics {cite}`scikit-learn`) can be taken from stable public sources. To maximize the readability and reproducibility of the experiment, a minimal setup was chosen, defining all necessary code, data, and requirements in one GitHub project {cite}`doi:10.5281/zenodo.17116549`.\n",
    "State-of-the-art Python packages are chosen, installed, and imported. The exact versions are shown in {numref}`table-requirements`. The Jupyter notebook is run locally on a Thinkpad T14 with an AMD Ryzen 5 PRO 5650U processor and 16 GB of memory but no GPU. The operating system is Linux Mint 22.1 and the Python kernel is version 3.12. We expect there to be no deviation in the results, even if different hardware or runtime is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d66bb14-108a-4841-861a-b42ba643461c",
   "metadata": {
    "label": "pip-install",
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib==1.0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: Pillow==11.3.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (11.3.0)\n",
      "Requirement already satisfied: numpy==2.1.3 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: pandas==2.3.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.3.1)\n",
      "Requirement already satisfied: tensorflow==2.19.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.19.0)\n",
      "Requirement already satisfied: scikit-learn==1.7.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from pandas==2.3.1->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from pandas==2.3.1->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tobsel/jupyter/lib/python3.12/site-packages (from pandas==2.3.1->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.11.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorflow==2.19.0->-r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from scikit-learn==1.7.1->-r requirements.txt (line 6)) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from scikit-learn==1.7.1->-r requirements.txt (line 6)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from scikit-learn==1.7.1->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tobsel/jupyter/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/tobsel/jupyter/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (14.1.0)\n",
      "Requirement already satisfied: namex in /home/tobsel/jupyter/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/tobsel/jupyter/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tobsel/jupyter/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/tobsel/jupyter/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0->-r requirements.txt (line 5)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!python3.12 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924ea3ec-3bbb-4d52-abc8-3e0bb525a32e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:37:13.927511: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-30 16:37:13.931430: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-30 16:37:13.939868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759243033.952973   17191 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759243033.956602   17191 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759243033.967795   17191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759243033.967838   17191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759243033.967843   17191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759243033.967846   17191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-30 16:37:13.971594: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# image & data processing\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import decode_predictions\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceedcb57-4c22-4606-976c-08bb4749df40",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Dependency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d907ab-b266-40bf-a018-0fa32fc5c01e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "package_versions = {}\n",
    "with open(\"requirements.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"==\" in line:\n",
    "            pkg, ver = line.split(\"==\")\n",
    "            package_versions[pkg] = ver\n",
    "        else:\n",
    "            package_versions[line] = \"unknown\"\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"package\": package_versions.keys(),\n",
    "    \"version\": package_versions.values()\n",
    "}).to_markdown(\"figure/requirements.md\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61db45b-40f7-4406-b31d-308bcefef014",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: table-requirements\n",
    ":align: center\n",
    "\n",
    "Runtime dependencies\n",
    "```{include} figure/requirements.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b4eec-e40d-49f3-a762-c6588b1b2cf5",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "After setting up the Python runtime and importing the required packages, we load the Inception-ResNet-v2 model from the TensorFlow model repository {cite}`tensorflow2015-whitepaper`. We use the publicly available pretrained weights, which were obtained by training the model on the ImageNet dataset {cite}`doi:10.1109/CVPR.2009.5206848`. This approach eliminates the model design and training phase completely but limits the model prediction space to the 1000 classes from the ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13ca2a5-58e7-465a-b892-e01b22f3a3d3",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:37:16.531312: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = InceptionResNetV2(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2756fa1-5497-4169-93a1-7ff0cd856622",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Carl et al. provide the source of the wildlife images used in their dataset {cite}`nationalpark2019schwarzwild`. This source is no longer available, requiring us to run the experiment on a different dataset. To test the generalizability of the model, we take a larger public dataset containing images of 90 different species {cite}`banerjee2024animal`. To mimic the original experiment setup, only 10 samples are used for each species, resulting in a total test sample size of 900 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c88843-7ffa-443b-9076-1c80ac52b33a",
   "metadata": {},
   "source": [
    "```{image} data/kaggle-90-different-animals/wombat/2a6c3fd292.jpg\n",
    ":align: center\n",
    ":alt: Example wildlife image (wombat)\n",
    ":width: 300px\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a09bccc-0d76-40f1-ac09-90cea5145796",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data/kaggle-90-different-animals\")\n",
    "GITHUB_PROJECT = \"https://github.com/tobsel7/research-vetmedwien-animal-species-identification\"\n",
    "input_shape = model.input_shape[1:3] # the required image dimensions (299, 299)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e7d79-7fb5-42b9-b80b-de313d1b4c5e",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We load the images, respecting all three color channels (RGB), resize them to 299 by 299 pixels, and convert them into a 1-dimensional vector. The color intensities are scaled to be floating-point numbers from 0 to 1. This is the minimal preprocessing required to fit the required input size of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40140f1-0592-413b-a60c-9aa9403ca6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, target_size):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = image.resize(target_size)\n",
    "    return np.array(image) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd76cbc-623f-434e-bcf1-fa3801b4d712",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "wildlife_image_paths = []\n",
    "\n",
    "animal_species = sorted([d.name for d in DATA_PATH.iterdir() if d.is_dir()])\n",
    "\n",
    "for species_name in animal_species:\n",
    "    animal_image_folder = DATA_PATH / species_name # every species has its image folder\n",
    "    for image_path in animal_image_folder.glob(\"*.jpg\"):\n",
    "        wildlife_image_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1c34b-5950-4d78-bbec-a6f9a540f6cd",
   "metadata": {},
   "source": [
    "Then we construct the testing dataset by stacking all normalized image vectors and using the folder names as the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c43f760-8384-41d0-9138-501329a5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_images = [load_image(p, input_shape) \n",
    "                 for p in wildlife_image_paths]\n",
    "animal_species = [p.parent.name \n",
    "                  for p in wildlife_image_paths]\n",
    "\n",
    "X_test = np.stack(animal_images, axis=0)\n",
    "y_true = animal_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03016731-0ae6-439a-940c-16ffd6f7afa4",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 299, 299, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c61ad-f992-446b-9b60-b72c2e764889",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "The Inception-ResNet-v2 model outputs a probability distribution over 1,000 classes, corresponding to the categories defined in the ImageNet dataset. For this study, we use only the top-1 prediction (the class with the highest softmax probability) as the model’s output and compare it to the ground-truth label from our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57705620-c7a5-416b-9393-57a72bf9ad80",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:37:31.143939: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 965530800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = [pred[0][1] # take output label\n",
    "          for pred \n",
    "          in decode_predictions(y_pred, top=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dc938-cbe0-42c5-937c-b2e2db96b132",
   "metadata": {},
   "source": [
    "When looking at the predictions, it becomes apparent that the model yields usable results. Almost all inference outputs are animal species somehow related to the one present in the image. The data already shows that the InceptionResNetV2 is generalizable to some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0b2297-2127-4b8f-bdd4-e02299daf908",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "species_recognition_result = pd.DataFrame({\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b09c22-5c7b-4126-8283-d32a367d547a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "species_recognition_result.groupby(\"y_true\", as_index=False).first()[[\"y_pred\", \"y_true\"]][:10].to_markdown(\"figure/species_recognition_result_raw_short.md\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353ed44-0309-4adc-87bf-f8845d10f55d",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: species_recognition_result_raw_short\n",
    ":align: center\n",
    "\n",
    "Subset of Inception-ResNet-v2 raw predictions\n",
    "```{include} figure/species_recognition_result_raw_short.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8e370-e4da-4ce2-9674-8b8379824f6a",
   "metadata": {},
   "source": [
    "## Label Mapping\n",
    "\n",
    "A key challenge in this setup is that ImageNet classes do not align directly with the wildlife species in our dataset. To enable evaluation, we constructed a manual mapping table linking model output labels to the target species. This mapping followed a best-effort approach based on the Linnean system of taxonomy.\n",
    "\n",
    "Several limitations arise from this process:\n",
    "\n",
    " - When we collapse multiple species into higher-level taxa (e.g., mapping all bear species to \"bear\"), we lose some species-level detail.\n",
    "\n",
    " - Certain species in the dataset are not represented in ImageNet classes at all (e.g., bats, deer), preventing meaningful predictions for these cases.\n",
    "\n",
    "While this mapping introduces ambiguity, it reflects a realistic challenge when applying pretrained ImageNet models to ecological data and illustrates the need for task-specific model adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f512d620-fdaa-42eb-a570-56e011303871",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "imagenet_to_kaggle = {\n",
    "    \"gazelle\": \"antelope\",\n",
    "    \"impala\": \"antelope\",\n",
    "    \"American_black_bear\": \"bear\",\n",
    "    \"brown_bear\": \"bear\",\n",
    "    \"ground_beetle\": \"beetle\",\n",
    "    \"leaf_beetle\": \"beetle\",\n",
    "    \"rhinoceros_beetle\": \"beetle\",\n",
    "    \"dung_beetle\": \"beetle\",\n",
    "    \"wild_boar\": \"boar\",\n",
    "    \"ringlet\": \"butterfly\",\n",
    "    \"monarch\": \"butterfly\",\n",
    "    \"sulphur_butterfly\": \"butterfly\",\n",
    "    \"lycaenid\": \"butterfly\",\n",
    "    \"Egyptian_cat\": \"cat\",\n",
    "    \"tabby\": \"cat\",\n",
    "    \"Siamese_cat\": \"cat\",\n",
    "    \"Persian_cat\": \"cat\",\n",
    "    \"lynx\": \"cat\",\n",
    "    \"water_buffalo\": \"cow\",\n",
    "    \"Dungeness_crab\": \"crab\",\n",
    "    \"red_deer\": \"deer\",\n",
    "    \"elk\": \"deer\",\n",
    "    \"Labrador_retriever\": \"dog\",\n",
    "    \"basset\": \"dog\",\n",
    "    \"Border_collie\": \"dog\",\n",
    "    \"Chihuahua\": \"dog\",\n",
    "    \"Bouvier_des_Flandres\": \"dog\",\n",
    "    \"Brittany_spaniel\": \"dog\",\n",
    "    \"English_setter\": \"dog\",\n",
    "    \"Greater_Swiss_Mountain_dog\": \"dog\",\n",
    "    \"Ibizan_hound\": \"dog\",\n",
    "    \"Mexican_hairless\": \"dog\",\n",
    "    \"tox_terrier\": \"dog\",\n",
    "    \"Pekinese\": \"dog\",\n",
    "    \"Pomeranian\": \"dog\", \n",
    "    \"golden_retriever\": \"dog\",\n",
    "    \"pug\": \"dog\",\n",
    "    \"ass\": \"donkey\",\n",
    "    \"mallard\": \"duck\",\n",
    "    \"bald_eagle\": \"eagle\",\n",
    "    \"golden_eagle\": \"eagle\",\n",
    "    \"African_elephant\": \"elephant\",\n",
    "    \"Indian_elephant\": \"elephant\",\n",
    "    \"Arctic_fox\": \"fox\",\n",
    "    \"red_fox\": \"fox\",\n",
    "    \"grey_fox\": \"fox\",\n",
    "    \"kit_fox\": \"fox\",\n",
    "    \"ibex\": \"goat\",\n",
    "    \"mountain_goat\": \"goat\",\n",
    "    \"Arabian_horse\": \"horse\",\n",
    "    \"Appaloosa\": \"horse\",\n",
    "    \"wallaby\": \"kangaroo\",\n",
    "    \"agama\": \"lizard\",\n",
    "    \"alligator_lizard\": \"lizard\",\n",
    "    \"banded_gecko\": \"lizard\",\n",
    "    \"Komodo_dragon\": \"lizard\",\n",
    "    \"whiptail\": \"lizard\", \n",
    "    \"American_lobster\": \"lobster\",\n",
    "    \"spiny_lobster\": \"lobster\",\n",
    "    \"house_mouse\": \"mouse\",\n",
    "    \"fiddler_crab\": \"crab\",\n",
    "    \"rock_crab\": \"crab\",\n",
    "    \"king_crab\": \"crab\",\n",
    "    \"magpie\": \"crow\",\n",
    "    \"jay\": \"crow\",\n",
    "    \"drake\": \"duck\",\n",
    "    \"tusker\": \"elephant\",\n",
    "    \"great_grey_owl\": \"owl\",\n",
    "    \"giant_panda\": \"panda\",\n",
    "    \"African_grey\": \"parrot\",\n",
    "    \"macaw\": \"parrot\",\n",
    "    \"sulphur-crested_cockatoo\": \"parrot\",\n",
    "    \"pelican\": \"pelecaniformes\",\n",
    "    \"black_stork\": \"pelecaniformes\",\n",
    "    \"king_penguin\": \"penguin\",\n",
    "    \"hog\": \"pig\",\n",
    "    \"red-backed_sandpiper\": \"sandpiper\",\n",
    "    \"redshank\": \"sandpiper\",\n",
    "    \"dowitcher\": \"sandpiper\",\n",
    "    \"great_white_shark\": \"shark\",\n",
    "    \"hammerhead\": \"shark\",\n",
    "    \"tiger_shark\": \"shark\",\n",
    "    \"horned_viper\": \"snake\",\n",
    "    \"ram\": \"sheep\",\n",
    "    \"bighorn\": \"sheep\",\n",
    "    \"vine_snake\": \"snake\",\n",
    "    \"king_snake\": \"snake\",\n",
    "    \"night_snake\": \"snake\",\n",
    "    \"Indian_cobra\": \"snake\",\n",
    "    \"ringneck_snake\": \"snake\",\n",
    "    \"rock_python\": \"snake\",\n",
    "    \"thunder_snake\": \"snake\",\n",
    "    \"fox_squirrel\": \"squirrel\",\n",
    "    \"black_swan\": \"swan\",\n",
    "    \"box_turtle\": \"turtle\",\n",
    "    \"loggerhead\": \"turtle\",\n",
    "    \"leatherback_turtle\": \"turtle\",\n",
    "    \"mud_turtle\": \"turtle\",\n",
    "    \"grey_whale\": \"whale\",\n",
    "    \"killer_whale\": \"whale\",\n",
    "    \"timber_wolf\": \"wolf\",\n",
    "    \"white_wolf\": \"wolf\"\n",
    "}\n",
    "\n",
    "y_pred_mapped = species_recognition_result[\"y_pred\"].map(\n",
    "    lambda l: imagenet_to_kaggle.get(l, l) # safe map accessor (labels that are not present in the dict keys, remain unchanged)\n",
    ")\n",
    "species_recognition_result[\"y_pred_mapped\"] = y_pred_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e219383-81b0-4e46-ab35-b39caca164ff",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "### Imagenet Label Mapping Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff4fc51-db9e-4471-82ce-5d57cc0eb868",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"ImageNet label\": imagenet_to_kaggle.keys(),\n",
    "    \"dataset label\": imagenet_to_kaggle.values()\n",
    "}).groupby(\"dataset label\")[\"ImageNet label\"].apply(\n",
    "    lambda labels: \", \".join(labels)\n",
    ").reset_index()[[\"ImageNet label\", \"dataset label\"]][:10].to_markdown(\"figure/imagenet_label_mapping_short.md\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497400d7-48af-4391-b5cb-2be51d2700b1",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: imagenet_label_mapping\n",
    ":align: center\n",
    "\n",
    "Mapping rules between ImageNet classes and test data classes\n",
    "```{include} figure/imagenet_label_mapping_short.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1bb2ff-e885-4ca9-8095-ceff8fe1a675",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Carl et al. reported two performance metrics for their study: overall classification accuracy across the dataset and per-species accuracy. To enable a direct comparison, we adopt the same evaluation strategy. After applying the label mapping described above, predictions are grouped by true species, and accuracy is computed at both the global and class levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54d64d76-4955-4fae-a9ff-2c5a6dd591a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b46fe9de-4ba5-4fb9-a165-66dc49cc2d8b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a917030d-7e9c-499f-bcbf-fcd60b4a9ba2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bison</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bear</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crab</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elephant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>reindeer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>squid</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sparrow</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>turkey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>woodpecker</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species  accuracy\n",
       "0        bison       1.0\n",
       "1         bear       1.0\n",
       "2         boar       1.0\n",
       "3         crab       1.0\n",
       "4     elephant       1.0\n",
       "..         ...       ...\n",
       "85    reindeer       0.0\n",
       "86       squid       0.0\n",
       "87     sparrow       0.0\n",
       "88      turkey       0.0\n",
       "89  woodpecker       0.0\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_accuracy = species_recognition_result.assign(\n",
    "    accuracy = species_recognition_result[\"y_true\"] == species_recognition_result[\"y_pred_mapped\"]\n",
    ").groupby(\"y_true\")[\"accuracy\"].mean().sort_values(ascending=False)\n",
    "group_accuracy = group_accuracy.reset_index()\n",
    "group_accuracy.columns = [\"species\", \"accuracy\"]\n",
    "group_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e716dd3-c719-4626-bdf1-6ccbf6f80bb9",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy\n",
       "0.0    26\n",
       "0.1     1\n",
       "0.3     3\n",
       "0.4     1\n",
       "0.6     1\n",
       "0.7     4\n",
       "0.8     6\n",
       "0.9    18\n",
       "1.0    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_accuracy.groupby(\"accuracy\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66631238-cecf-4ed5-9f4f-fcecfc570d1f",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Group Accuracy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa4b1d98-c1f2-4dde-bf3f-caf6b167369e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "summary_grouped = (\n",
    "    group_accuracy.groupby(\"accuracy\")[\"species\"]\n",
    "    .apply(lambda x: \", \".join(x))\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"accuracy\", ascending=False)\n",
    ")[[\"species\", \"accuracy\"]]\n",
    "\n",
    "md_table = pd.concat([\n",
    "    summary_grouped,\n",
    "    pd.DataFrame([[\"TOTAL\", accuracy]], columns=[\"species\", \"accuracy\"])\n",
    "], ignore_index=True)\n",
    "\n",
    "md_table.to_markdown(\"figure/species_recognition_result_summary.md\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f40159-ba3e-4f61-b036-ee8d976dbd79",
   "metadata": {},
   "source": [
    "```{table} \n",
    ":name: species_recognition_result_summary\n",
    ":align: center\n",
    "\n",
    "Prediction accuracy per species and the total accuracy\n",
    "```{include} figure/species_recognition_result_summary.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bc3b2-7243-4663-a109-44c1ceab5ca9",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Our reproduced results confirm the findings of Carl et al. We achieve an overall top-1 prediction accuracy of 62% by using a larger dataset that includes many species not present in the original study. This result is comparable to the 71% reported by Carl et al. Consistent with their study, we observe substantial variation in per-species accuracies. 48 species out of 90 are predicted with an accuracy greater than or equal to 90%, and 26 species are predicted without any success (0% accuracy). A detailed summary of per-species prediction accuracies is provided in {numref}`species_recognition_result_summary`.\n",
    "\n",
    "The experiment shows that pretrained convolutional neural networks, like the Inception-ResNet-v2, are a viable option for the annotation of camera trap images. The network design allows for detailed pattern recognition and robust identification of a large number of animal species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1657b70-9021-4849-9e20-ad8d18353e74",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "Prior research has explored transfer learning of convolutional neural networks for recognizing animals and their facial features, showing that retraining pretrained networks for a specific use case can substantially improve prediction accuracy {cite}`doi:10.3390/app13021178`.\n",
    "The investigated model is still very deep (about 55 million parameters) and therefore less suitable for outdoor deployment with strict energy limitations and memory constraints. Other similar models, like MobileNet {cite}`doi:10.1109/ICCV.2019.00140` and EfficientNet {cite}`doi:10.48550/arXiv.1905.11946` variants, use significantly fewer layers and can realistically be deployed in nature for live animal identification. Future work could evaluate these smaller models following the same experimental approach. Combining them with transfer learning may yield highly efficient and accurate models suitable for deployment in real-world wildlife monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4cafb-91a2-42d0-84cd-12f62816805b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "# Experiment Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1f8c9-6a23-4f9f-b603-42008a0a5089",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Inference Output Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16fc0cdf-5032-40d7-9f29-7c213f19e781",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "github_animal_image_paths = [\n",
    "    f\"{GITHUB_PROJECT}/raw/main/{p}\"\n",
    "    for p in wildlife_image_paths\n",
    "]\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"image link\": github_animal_image_paths,\n",
    "    \"truth\": species_recognition_result[\"y_true\"],\n",
    "    \"mapped prediction\": species_recognition_result[\"y_pred_mapped\"],\n",
    "    \"model prediction\": species_recognition_result[\"y_pred\"]\n",
    "}).to_csv(\"figure/model_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
